{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collect-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from kapre.time_frequency import STFT, Magnitude, ApplyFilterbank, MagnitudeToDecibel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "\n",
    "def envelope(y, rate, threshold):\n",
    "    mask = []\n",
    "    y = pd.Series(y).apply(np.abs)\n",
    "    y_mean = y.rolling(window=int(rate/20),\n",
    "                       min_periods=1,\n",
    "                       center=True).max()\n",
    "    for mean in y_mean:\n",
    "        if mean > threshold:\n",
    "            mask.append(True)\n",
    "        else:\n",
    "            mask.append(False)\n",
    "    return mask, y_mean\n",
    "\n",
    "'''\n",
    "Make prediction for one file\n",
    "'''\n",
    "def make_prediction(args):\n",
    "    \n",
    "    model = load_model(args.model_fn,\n",
    "        custom_objects={'STFT':STFT,\n",
    "                        'Magnitude':Magnitude,\n",
    "                        'ApplyFilterbank':ApplyFilterbank,\n",
    "                        'MagnitudeToDecibel':MagnitudeToDecibel})\n",
    "    src_dir = args.src_dir\n",
    "    wav_paths = glob('{}/**'.format(src_dir), recursive=True)\n",
    "    wav_paths = sorted([x.replace(os.sep, '/') for x in wav_paths if '.wav' in x])\n",
    "    wav_path = [x for x in wav_paths if args.fn in x]\n",
    "    if len(wav_path) != 1:\n",
    "        print('audio file not found for sub-string: {}'.format(args.fn))\n",
    "        return\n",
    "    classes = sorted(os.listdir(args.src_dir))\n",
    "    results = []\n",
    "    \n",
    "    wav, rate = librosa.load(wav_path[0], args.sr)\n",
    "    mask, env = envelope(wav, rate, threshold=args.threshold)\n",
    "    clean_wav = wav[mask]\n",
    "    step = int(args.sr*args.dt)\n",
    "    batch = []\n",
    "\n",
    "    # Append samples located in same audio file as batch\n",
    "    for i in range(0, clean_wav.shape[0], step):\n",
    "        sample = clean_wav[i:i+step]\n",
    "        sample = sample.reshape(-1, 1)\n",
    "        if sample.shape[0] < step:\n",
    "            tmp = np.zeros(shape=(step, 1), dtype=np.float32)\n",
    "            tmp[:sample.shape[0],:] = sample.flatten().reshape(-1, 1)\n",
    "            sample = tmp\n",
    "        batch.append(sample)\n",
    "\n",
    "    # Sum all the prediction probability of each sample batches in audio file and get mean values\n",
    "    # Find maximum prediction probability from mean values\n",
    "    X_batch = np.array(batch, dtype=np.float32)\n",
    "    y_pred = model.predict(X_batch)\n",
    "    y_mean = np.mean(y_pred, axis=0)\n",
    "    y_pred = np.argmax(y_mean)\n",
    "    real_class = os.path.dirname(wav_path[0]).split('/')[-1]\n",
    "    print('Actual class: {}, Predicted class: {}'.format(real_class, classes[y_pred]))\n",
    "    results.append(y_mean)\n",
    "    \n",
    "'''\n",
    "Make predictions for multiple files\n",
    "'''    \n",
    "def make_predictions(args):\n",
    "\n",
    "    model = load_model(args.model_fn,\n",
    "        custom_objects={'STFT':STFT,\n",
    "                        'Magnitude':Magnitude,\n",
    "                        'ApplyFilterbank':ApplyFilterbank,\n",
    "                        'MagnitudeToDecibel':MagnitudeToDecibel})\n",
    "    wav_paths = glob('{}/**'.format(args.src_dir), recursive=True)\n",
    "    wav_paths = sorted([x.replace(os.sep, '/') for x in wav_paths if '.wav' in x])\n",
    "    classes = sorted(os.listdir(args.src_dir))\n",
    "    labels = [os.path.split(x)[0].split('/')[-1] for x in wav_paths]\n",
    "    le = LabelEncoder()\n",
    "    y_true = le.fit_transform(labels)\n",
    "    results = []\n",
    "\n",
    "    for z, wav_fn in enumerate(wav_paths):\n",
    "        wav, rate = librosa.load(wav_fn, args.sr)\n",
    "        mask, env = envelope(wav, rate, threshold=args.threshold)\n",
    "        clean_wav = wav[mask]\n",
    "        step = int(args.sr*args.dt)\n",
    "        batch = []\n",
    "\n",
    "        for i in range(0, clean_wav.shape[0], step):\n",
    "            sample = clean_wav[i:i+step]\n",
    "            sample = sample.reshape(-1, 1)\n",
    "            if sample.shape[0] < step:\n",
    "                tmp = np.zeros(shape=(step, 1), dtype=np.float32)\n",
    "                tmp[:sample.shape[0],:] = sample.flatten().reshape(-1, 1)\n",
    "                sample = tmp\n",
    "            batch.append(sample)\n",
    "        X_batch = np.array(batch, dtype=np.float32)\n",
    "        y_pred = model.predict(X_batch)\n",
    "        y_mean = np.mean(y_pred, axis=0)\n",
    "        print(np.round_(y_mean, 2))\n",
    "        y_pred = np.argmax(y_mean)\n",
    "        real_class = os.path.dirname(wav_fn).split('/')[-1]\n",
    "        print('Actual class: {}, Predicted class: {}'.format(real_class, classes[y_pred]))\n",
    "        results.append(y_mean)\n",
    "\n",
    "    np.save(os.path.join('./logs', args.pred_fn), np.array(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "needed-order",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'batch_outputs' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9f7b742395a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#make_prediction(args)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mmake_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-1e945fa32d02>\u001b[0m in \u001b[0;36mmake_predictions\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0my_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1612\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'outputs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1614\u001b[1;33m     \u001b[0mall_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure_up_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1615\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'batch_outputs' referenced before assignment"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Audio Classification Training')\n",
    "    parser.add_argument('--model_fn', type=str, default='./models/conv1d.h5',\n",
    "                        help='model file to make predictions')\n",
    "    parser.add_argument('--pred_fn', type=str, default='y_pred',\n",
    "                        help='fn to write predictions in logs dir')\n",
    "    parser.add_argument('--src_dir', type=str, default='../Thingy52/testdata',\n",
    "                        help='directory containing wavfiles to predict')\n",
    "    parser.add_argument('--fn', type=str, default='7064-6-0-0.wav',\n",
    "                        help='file name to predict')\n",
    "    parser.add_argument('--dt', type=float, default=1.0,\n",
    "                        help='time in seconds to sample audio')\n",
    "    parser.add_argument('--sr', type=int, default=16000,\n",
    "                        help='sample rate of clean audio')\n",
    "    parser.add_argument('--threshold', type=str, default=0.00,\n",
    "                        help='threshold magnitude for np.int16 dtype')\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    #make_prediction(args)\n",
    "    make_predictions(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-preserve",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
